#!/usr/bin/env python3
import torch;
import torch.nn as nn
import torch.nn.functional as F
import torch.utils
import torch.distributions
import numpy as np
import math
import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 100
from cog_learning.nn_ga import *
from cog_learning.msg import LatentGoalDnf
from cog_learning.msg import LatentGoalNN
import rospy
from std_msgs.msg import Float64
from std_msgs.msg import Int16
from std_msgs.msg import Bool
from motion.msg import Dmp
from motion.msg import Action
from motion.msg import DmpAction
from motion.msg import DmpOutcome
from detector.msg import Outcome
from detector.msg import State
from cluster_message.msg import SampleExplore
from cluster_message.msg import SampleExploit
from cv_bridge import CvBridge, CvBridgeError
from sensor_msgs.msg import Image

try:
    import cPickle as pickle
except ModuleNotFoundError:
    import pickle

is_cuda = torch.cuda.is_available()
#device = torch.device("cpu")

if not is_cuda:
    device = torch.device("cuda")
    print("GPU is available")
else:
    device = torch.device("cpu")
    print("GPU not available, CPU used")

class Exploitation(object):
    def __init__(self):
        rospy.init_node('exploitation', anonymous=True)
        self.bridge = CvBridge()
        self.pub_field = rospy.Publisher("/cog_learning/cedar/mt", Image, queue_size=1, latch=True)
        self.pub_mt_error = rospy.Publisher("/cog_learning/cedar/mt_error", Image, queue_size=1, latch=True)
        self.pub_mt_lp = rospy.Publisher("/cog_learning/cedar/mt_lp", Image, queue_size=1, latch=True)
        self.load = rospy.get_param("load_nnga")
        self.folder_nnga = rospy.get_param("nnga_folder")
        self.nn_goalactions = []
        self.id_nnga = 0
        self.prev_id_nnga = -1 
        self.index_nnga = -1
        self.id_defined = False
        self.dmp = Dmp()
        self.action_sample = Action()
        self.state_obj = State()
        self.dmp_outcome = DmpOutcome()
        self.outcome = Outcome()
        self.sample_explore = SampleExplore()
        self.sample_exploit = SampleExploit()
        self.incoming_dmp = False
        self.incoming_outcome = False
        self.current_dmp = -1
        self.sample = False
        self.state = False
        self.tot_lout = 0
        self.tot_nout = 0
        self.tot_lact = 0
        self.tot_nact = 0
        self.busy_out_learning = False
        self.busy_out_not_learning = False
        self.busy_act_learning = False
        self.busy_act_not_learning = False
        rospy.Subscriber("/cluster_msg/sample_explore", SampleExplore, self.callback_sample_explore)
        rospy.Subscriber("/cluster_msg/sample_exploit", SampleExploit, self.callback_sample_exploit)
        rospy.Subscriber("/cog_learning/activate_goal", LatentGoalDnf, self.callback_latent)
        rospy.Subscriber("/cog_learning/id_object", Int16, self.callback_id)
        rospy.Subscriber("/cog_learning/mt", Image, self.field_callback)
        rospy.Subscriber("/cog_learning/mt_error", Image, self.error_callback)
        rospy.Subscriber("/cog_learning/mt_lp", Image, self.lp_callback)
        rospy.Subscriber("/cog_learning/outcome/learning", Float64, self.callback_learning_out)
        rospy.Subscriber("/cog_learning/outcome/not_learning", Float64, self.callback_not_out)
        rospy.Subscriber("/cog_learning/action/learning", Float64, self.callback_learning_act)
        rospy.Subscriber("/cog_learning/action/not_learning", Float64, self.callback_not_act)
        if self.load:
            self.load_memory()

    def callback_sample_explore(self, msg):
        print("NNGA got sample explore")
        self.sample_explore.state_x = msg.state_x
        self.sample_explore.state_y = msg.state_y
        self.sample_explore.state_angle = msg.state_angle
        self.sample_explore.v_x = msg.v_x
        self.sample_explore.v_y = msg.v_y
        self.sample_explore.v_pitch = msg.v_pitch
        self.sample_explore.roll = msg.roll
        self.sample_explore.grasp = msg.grasp
        self.sample_explore.lpos_x = msg.lpos_x
        self.sample_explore.lpos_y = msg.lpos_y
        self.sample_explore.lpos_pitch = msg.lpos_pitch
        self.sample_explore.outcome_x = msg.outcome_x
        self.sample_explore.outcome_y = msg.outcome_y
        self.sample_explore.outcome_angle = msg.outcome_angle
        self.sample_explore.outcome_touch = msg.outcome_touch
        self.nn_goalactions[self.index_nnga].bootstrap_learning(msg)

    def callback_sample_exploit(self, msg):
        self.sample_exploit.lpos_x = msg.lpos_x
        self.sample_exploit.lpos_y = msg.lpos_y
        self.sample_exploit.lpos_pitch = msg.lpos_pitch
        self.sample_exploit.outcome_x = msg.outcome_x
        self.sample_exploit.outcome_y = msg.outcome_y
        self.sample_exploit.outcome_angle = msg.outcome_angle
        self.sample_exploit.outcome_touch = msg.outcome_touch
        self.sample_exploit.state_x = msg.state_x
        self.sample_exploit.state_y = msg.state_y
        self.sample_exploit.state_angle = msg.state_angle
        self.sample_exploit.dnf_x = msg.dnf_x
        self.sample_exploit.dnf_y = msg.dnf_y
        self.nn_goalactions[self.index_nnga].continue_learning(self.sample_exploit)

    #get latent goal DNF, send dmp to controller, set current goal for fwd and inv model 
    def callback_latent(self, msg):
        #print("Received Latent Goal : ",msg)
        goal_nn = LatentGoalNN()
        #x = msg.latent_x / 100
        #y = msg.latent_y / 100
        x_1 = self.nn_goalactions[self.index_nnga].scale_dnf_to_latent(msg.latent_x)
        y_1 = self.nn_goalactions[self.index_nnga].scale_dnf_to_latent(msg.latent_y)
        goal_nn.latent_x = self.nn_goalactions[self.index_nnga].scale_latent_to_reduce(x_1)
        goal_nn.latent_y = self.nn_goalactions[self.index_nnga].scale_latent_to_reduce(y_1)
        print("Latent tensor scaled ---",goal_nn)
        self.nn_goalactions[self.index_nnga].activate_dmp_actions(msg)
        #self.nn_goalactions[self.index_nnga].activate_hebbian(msg)
        #self.nn_goalactions[self.index_nnga].send_habituation(goal_nn)

    def callback_id(self, msg):
        if self.prev_id_nnga != self.id_nnga and msg.data != -1:
            self.id_nnga = msg.data
            found = False
            for i in range(0,len(self.nn_goalactions)):
                tmp = self.nn_goalactions[i].get_id()
                if tmp == self.id_nnga:
                    self.index_nnga = i
                    found = True
                    print("found object, sending latent space and MT...")
                    self.send_mt_field()
                    self.send_mt_error()
                    self.send_mt_lp()
            if not found:
                print("Creating new NNGA")
                goal_action = NNGoalAction(self.id_nnga)
                self.nn_goalactions.append(goal_action)
                self.index_nnga = len(self.nn_goalactions) - 1
                blank_mt = np.zeros((100,100,1), np.float32)
                self.nn_goalactions[self.index_nnga].set_mt_field(blank_mt)
                self.nn_goalactions[self.index_nnga].set_mt_error(blank_mt)
                self.nn_goalactions[self.index_nnga].set_mt_lp(blank_mt)
                self.send_mt_field()
                self.send_mt_error()
                self.send_mt_lp()
            self.prev_id_nnga = self.id_nnga
            self.id_defined = True

    def field_callback(self,msg):
        try:
            # Convert your ROS Image message to OpenCV2
            cv2_img = self.bridge.imgmsg_to_cv2(msg, "32FC1")
            if self.id_defined:
                self.nn_goalactions[self.index_nnga].set_mt_field(cv2_img)
        except CvBridgeError as e:
            print(e)

    def error_callback(self,msg):
        try:
            # Convert your ROS Image message to OpenCV2
            cv2_img = self.bridge.imgmsg_to_cv2(msg, "32FC1")
            if self.id_defined:
                self.nn_goalactions[self.index_nnga].set_mt_error(cv2_img)
        except CvBridgeError as e:
            print(e)

    def lp_callback(self,msg):
        try:
            # Convert your ROS Image message to OpenCV2
            cv2_img = self.bridge.imgmsg_to_cv2(msg, "32FC1")
            if self.id_defined:
                self.nn_goalactions[self.index_nnga].set_mt_lp(cv2_img)
        except CvBridgeError as e:
            print(e)

    def callback_learning_out(self,msg):
        if msg.data > 0.9:
            self.tot_lout += 1
        else:
            self.tot_lout = 0
            self.busy_out_learning = False
        if self.tot_lout > 10 and not self.busy_out_learning:
            self.busy_out_learning = True
            self.bootstrap_learning()


    def callback_not_out(self,msg):
        if msg.data > 0.9:
            self.tot_nout += 1
        else:
            self.tot_nout = 0
            self.busy_out_not_learning = False
        if self.tot_nout > 10 and not self.busy_out_not_learning:
            self.busy_out_not_learning = True
            self.bootstrap_learning()

    def callback_learning_act(self,msg):
        if msg.data > 0.9:
            self.tot_lact += 1
        else:
            self.tot_lact = 0
            self.busy_act_learning = False
        if self.tot_lact > 10 and not self.busy_act_learning:
            self.busy_act_learning = True
            self.bootstrap_learning()

    def callback_not_act(self,msg):
        if msg.data > 0.9:
            self.tot_nact += 1
        else:
            self.tot_nact = 0
            self.busy_act_not_learning = False
        if self.tot_nact > 10 and not self.busy_act_not_learning:
            self.busy_act_not_learning = True
            self.bootstrap_learning()

    def bootstrap_learning(self):
        if self.busy_out_learning and self.busy_act_learning:
            #both learning
            self.nn_goalactions[self.index_nnga].bootstrap_learning(True,True,self.sample_explore)
        if self.busy_out_learning and self.busy_act_not_learning:
            #new outcome but old action
            self.nn_goalactions[self.index_nnga].bootstrap_learning(True,False,self.sample_explore)
        if self.busy_out_not_learning and self.busy_act_learning:
            #existing outcome and new action
            self.nn_goalactions[self.index_nnga].bootstrap_learning(False,True,self.sample_explore)
        if self.busy_out_not_learning and self.busy_act_not_learning:
            #not learning AE but create new hebbian connections between outcome and action
            self.nn_goalactions[self.index_nnga].bootstrap_learning(False,False,self.sample_explore)

    def send_mt_field(self):
        img_field = self.nn_goalactions[self.index_nnga].get_mt_field()
        img_msg = self.bridge.cv2_to_imgmsg(img_field, encoding="passthrough")
        self.pub_field.publish(img_msg)

    def send_mt_error(self):
        img_field = self.nn_goalactions[self.index_nnga].get_mt_error()
        img_msg = self.bridge.cv2_to_imgmsg(img_field, encoding="passthrough")
        self.pub_mt_error.publish(img_msg)

    def send_mt_lp(self):
        img_field = self.nn_goalactions[self.index_nnga].get_mt_lp()
        img_msg = self.bridge.cv2_to_imgmsg(img_field, encoding="passthrough")
        self.pub_mt_lp.publish(img_msg)

    def load_memory(self):
        list_dir = os.listdir(self.folder_nnga)
        for i in range(0,len(list_dir)):
            tmp_nnga = NNGoalAction(i)
            tmp_nnga.load_memory(i)
            tmp_nnga.load_nn(i)
            tmp_nnga.load_skills(i)
            self.nn_goalactions.append(tmp_nnga)
        s = []
        l = []
        for i in self.nn_goalactions:
            s = i.get_skills()
            l = i.get_latent_space_dnf()
            print("nnga number : ",i.get_id())
            print("Latent DNF : ",l)
            for i in s:
                print("skill : ",i.get_name())
                print("memory : ",i.get_memory())
        


        
if __name__ == "__main__":
    
    """nn_ga = NNGoalAction()
    goal = [0.1,0.1,0.5,0.2,0.3,0.3,0.1,0.1]
    sec_goal = [0.4,0.4,0.1,0.6,0.1]
    third_goal = [0.2,0.34,0.12,0.43,0.8]
    test_goal = [0.1,0.1,0.5,0.3,0.3]
    tensor_goal = torch.tensor(goal,dtype=torch.float)
    nn_ga.add_to_memory(tensor_goal)
    res = nn_ga.forward_encoder(tensor_goal)
    print("Inputs goal ",goal)
    print("Output encoder ",res)
    res2 = nn_ga.forward_decoder(res)
    print("Output decoder before training ",res2)
    nn_ga.trainDecoder()
    res3 = nn_ga.forward_decoder(res)
    print("Output decoder after training ",res3)
    res = nn_ga.forward_encoder(tensor_goal)
    print("Output encoder ",res)
    #print("RECONSTRUCTION 2",res2)
    #print("RECONSTRUCTION 3",res3)"""
    exploit = Exploitation()
    rospy.spin()