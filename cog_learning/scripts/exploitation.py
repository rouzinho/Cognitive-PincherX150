#!/usr/bin/env python3
import torch;
import torch.nn as nn
import torch.nn.functional as F
import torch.utils
import torch.distributions
import numpy as np
import math
import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 100
from cog_learning.nn_ga import *
import rospy
from std_msgs.msg import Float64
from std_msgs.msg import Int16
from std_msgs.msg import Bool
from motion.msg import Dmp
from motion.msg import Action
from motion.msg import DmpAction
from detector.msg import Outcome

try:
    import cPickle as pickle
except ModuleNotFoundError:
    import pickle

is_cuda = torch.cuda.is_available()
#device = torch.device("cpu")

if not is_cuda:
    device = torch.device("cuda")
    print("GPU is available")
else:
    device = torch.device("cpu")
    print("GPU not available, CPU used")

class Exploitation(object):
    def __init__(self):
        rospy.init_node('exploitation', anonymous=True)
        rospy.Subscriber("/exploration", Bool, self.callback_exploration)
        rospy.Subscriber("/exploitation", Bool, self.callback_exploitation)
        rospy.Subscriber("/motion_pincher/dmp_param", Dmp, self.callback_dmp)
        rospy.Subscriber("/outcome_detector/outcome", Outcome, self.callback_outcome)
        rospy.Subscriber("/motion_pincher/action_sample", Action, self.callback_sample)
        rospy.Subscriber("/motion_pincher/dmp_action", DmpAction, self.callback_dmp_action)
        self.nn_goalactions = []
        self.explore = False
        self.exploitation = False
        self.dmp = Dmp()
        self.dmp_action = DmpAction()
        self.outcome = Outcome()
        self.incoming_dmp = False
        self.incoming_outcome = False
        self.current_dmp = -1
        self.sample = Action()

    def callback_exploration(self, msg):
        self.explore = msg.data

    def callback_exploitation(self, msg):
        self.exploitation = msg.data

    def callback_dmp(self, msg):
        print("got DMP")
        self.dmp.v_x = msg.v_x
        self.dmp.v_y = msg.v_y
        self.dmp.v_pitch = msg.v_pitch
        self.dmp.roll = msg.roll
        self.dmp.grasp = msg.grasp
        

    def callback_outcome(self, msg):
        print("got outcome")
        self.outcome.state_x = msg.state_x
        self.outcome.state_y = msg.state_y
        self.outcome.state_angle = msg.state_angle
        self.outcome.x = msg.x
        self.outcome.y = msg.y
        self.outcome.angle = msg.angle
        self.outcome.touch = msg.touch
        self.incoming_outcome = True
        if(self.incoming_dmp and self.incoming_outcome):
            ind = len(self.nn_goalactions)
            goal_action = NNGoalAction()
            self.nn_goalactions.append(goal_action)
            self.nn_goalactions[ind].bootstrap_learning(self.outcome,self.dmp)
            self.incoming_outcome = False

    def callback_sample(self, msg):
        pass

    def callback_dmp_action(self, msg):
        print("got DMP ACTION")
        self.dmp_action.v_x = msg.v_x
        self.dmp_action.v_y = msg.v_y
        self.dmp_action.v_pitch = msg.v_pitch
        self.dmp_action.roll = msg.roll
        self.dmp_action.grasp = msg.grasp
        self.dmp_action.lpos_x = msg.lpos_x
        self.dmp_action.lpos_y = msg.lpos_y
        self.dmp_action.lpos_pitch = msg.lpos_pitch
        self.incoming_dmp = True
        if(self.incoming_dmp and self.incoming_outcome):
            ind = len(self.nn_goalactions)
            goal_action = NNGoalAction()
            self.nn_goalactions.append(goal_action)
            self.nn_goalactions[ind].bootstrap_learning(self.outcome,self.dmp_action)
            self.incoming_dmp = False


        
if __name__ == "__main__":
    torch.manual_seed(58)
    """nn_ga = NNGoalAction()
    goal = [0.1,0.1,0.5,0.2,0.3,0.3,0.1,0.1]
    sec_goal = [0.4,0.4,0.1,0.6,0.1]
    third_goal = [0.2,0.34,0.12,0.43,0.8]
    test_goal = [0.1,0.1,0.5,0.3,0.3]
    tensor_goal = torch.tensor(goal,dtype=torch.float)
    nn_ga.add_to_memory(tensor_goal)
    res = nn_ga.forward_encoder(tensor_goal)
    print("Inputs goal ",goal)
    print("Output encoder ",res)
    res2 = nn_ga.forward_decoder(res)
    print("Output decoder before training ",res2)
    nn_ga.trainDecoder()
    res3 = nn_ga.forward_decoder(res)
    print("Output decoder after training ",res3)
    res = nn_ga.forward_encoder(tensor_goal)
    print("Output encoder ",res)
    #print("RECONSTRUCTION 2",res2)
    #print("RECONSTRUCTION 3",res3)"""
    exploit = Exploitation()
    rospy.spin()