#!/usr/bin/env python3
import torch;
import torch.nn as nn
import torch.nn.functional as F
import torch.utils
import torch.distributions
import numpy as np
import math
import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 100
from cog_learning.nn_ga import *
import rospy
from std_msgs.msg import Float64
from std_msgs.msg import Int16
from std_msgs.msg import Bool
from motion.msg import Dmp
from motion.msg import Action
from motion.msg import DmpAction
from motion.msg import DmpOutcome
from detector.msg import Outcome
from detector.msg import State

try:
    import cPickle as pickle
except ModuleNotFoundError:
    import pickle

is_cuda = torch.cuda.is_available()
#device = torch.device("cpu")

if not is_cuda:
    device = torch.device("cuda")
    print("GPU is available")
else:
    device = torch.device("cpu")
    print("GPU not available, CPU used")

class Exploitation(object):
    def __init__(self):
        rospy.init_node('exploitation', anonymous=True)
        rospy.Subscriber("/cog_learning/exploration", Bool, self.callback_exploration)
        rospy.Subscriber("/cog_learning/exploitation", Bool, self.callback_exploitation)
        rospy.Subscriber("/cog_learning/dmp_outcome", DmpOutcome, self.callback_dmp_outcome)
        rospy.Subscriber("/cog_learning/object_state", State, self.callback_state)
        rospy.Subscriber("/motion_pincher/action_sample", Action, self.callback_sample)
        rospy.Subscriber("/motion_pincher/dmp_action", DmpAction, self.callback_dmp_action)
        self.nn_goalactions = []
        self.explore = False
        self.exploitation = False
        self.dmp = Dmp()
        self.action_sample = Action()
        self.state_obj = State()
        self.dmp_outcome = DmpOutcome()
        self.outcome = Outcome()
        self.incoming_dmp = False
        self.incoming_outcome = False
        self.current_dmp = -1
        self.sample = False
        self.state = False

    def callback_exploration(self, msg):
        self.explore = msg.data

    def callback_exploitation(self, msg):
        self.exploitation = msg.data

    def callback_sample(self, msg):
        self.action_sample.lpos_x = msg.lpos_x
        self.action_sample.lpos_y = msg.lpos_y
        self.action_sample.lpos_pitch = msg.lpos_pitch
        self.sample = True

    def callback_state(self, msg):
        self.state_obj.state_x = msg.state_x
        self.state_obj.state_y = msg.state_y
        self.state_obj.state_angle = msg.state_angle
        self.state = True

    def callback_dmp_outcome(self, msg):
        self.dmp_outcome.v_x = msg.v_x
        self.dmp_outcome.v_y = msg.v_y
        self.dmp_outcome.v_pitch = msg.v_pitch
        self.dmp_outcome.roll = msg.roll
        self.dmp_outcome.grasp = msg.grasp
        self.dmp_outcome.x = msg.x
        self.dmp_outcome.y = msg.y
        self.dmp_outcome.angle = msg.angle
        self.dmp_outcome.touch = msg.touch
        if (self.sample and self.state):
            outcome = Outcome()
            outcome.state_x = self.state_obj.state_x
            outcome.state_y = self.state_obj.state_y
            outcome.state_angle = self.state_obj.state_angle
            outcome.x = msg.x
            outcome.y = msg.y
            outcome.angle = msg.angle
            outcome.touch = msg.touch
            dmp_action = DmpAction()
            dmp_action.v_x = msg.v_x
            dmp_action.v_y = msg.v_y
            dmp_action.v_pitch = msg.v_pitch
            dmp_action.roll = msg.roll
            dmp_action.grasp = msg.grasp
            dmp_action.lpos_x = self.action_sample.lpos_x
            dmp_action.lpos_y = self.action_sample.lpos_y
            dmp_action.lpos_pitch = self.action_sample.lpos_pitch
            ind = len(self.nn_goalactions)
            goal_action = NNGoalAction()
            self.nn_goalactions.append(goal_action)
            self.nn_goalactions[ind].bootstrap_learning(outcome,dmp_action)
            self.sample = False
            self.sample = False

    def callback_dmp_action(self, msg):
        print("got DMP ACTION")
        self.dmp_action.v_x = msg.v_x
        self.dmp_action.v_y = msg.v_y
        self.dmp_action.v_pitch = msg.v_pitch
        self.dmp_action.roll = msg.roll
        self.dmp_action.grasp = msg.grasp
        self.dmp_action.lpos_x = msg.lpos_x
        self.dmp_action.lpos_y = msg.lpos_y
        self.dmp_action.lpos_pitch = msg.lpos_pitch
        self.incoming_dmp = True
        if(self.incoming_dmp and self.incoming_outcome):
            ind = len(self.nn_goalactions)
            goal_action = NNGoalAction()
            self.nn_goalactions.append(goal_action)
            self.nn_goalactions[ind].bootstrap_learning(self.outcome,self.dmp_action)
            self.incoming_dmp = False


        
if __name__ == "__main__":
    
    """nn_ga = NNGoalAction()
    goal = [0.1,0.1,0.5,0.2,0.3,0.3,0.1,0.1]
    sec_goal = [0.4,0.4,0.1,0.6,0.1]
    third_goal = [0.2,0.34,0.12,0.43,0.8]
    test_goal = [0.1,0.1,0.5,0.3,0.3]
    tensor_goal = torch.tensor(goal,dtype=torch.float)
    nn_ga.add_to_memory(tensor_goal)
    res = nn_ga.forward_encoder(tensor_goal)
    print("Inputs goal ",goal)
    print("Output encoder ",res)
    res2 = nn_ga.forward_decoder(res)
    print("Output decoder before training ",res2)
    nn_ga.trainDecoder()
    res3 = nn_ga.forward_decoder(res)
    print("Output decoder after training ",res3)
    res = nn_ga.forward_encoder(tensor_goal)
    print("Output encoder ",res)
    #print("RECONSTRUCTION 2",res2)
    #print("RECONSTRUCTION 3",res3)"""
    exploit = Exploitation()
    rospy.spin()